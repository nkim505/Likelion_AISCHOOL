{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54f370fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_tabnet"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/dreamquark-ai/tabnet.git 'C:\\Users\\Yeonjun Jeong\\AppData\\Local\\Temp\\pip-install-mgb58r0p\\pytorch-tabnet_08c9b18bfa7745b4a678187b43e636a6'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Cloning https://github.com/dreamquark-ai/tabnet.git (to revision develop) to c:\\users\\yeonjun jeong\\appdata\\local\\temp\\pip-install-mgb58r0p\\pytorch-tabnet_08c9b18bfa7745b4a678187b43e636a6\n",
      "  Resolved https://github.com/dreamquark-ai/tabnet.git to commit 40107a80b0be5ae865d945b85a52e5d99fc19a81\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in c:\\users\\yeonjun jeong\\anaconda3\\lib\\site-packages (from pytorch_tabnet) (1.19.5)\n",
      "Requirement already satisfied: torch<2.0,>=1.2 in c:\\users\\yeonjun jeong\\anaconda3\\lib\\site-packages (from pytorch_tabnet) (1.11.0)\n",
      "Requirement already satisfied: scipy>1.4 in c:\\users\\yeonjun jeong\\anaconda3\\lib\\site-packages (from pytorch_tabnet) (1.6.2)\n",
      "Requirement already satisfied: scikit_learn>0.21 in c:\\users\\yeonjun jeong\\anaconda3\\lib\\site-packages (from pytorch_tabnet) (0.24.1)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.36 in c:\\users\\yeonjun jeong\\anaconda3\\lib\\site-packages (from pytorch_tabnet) (4.59.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\yeonjun jeong\\anaconda3\\lib\\site-packages (from scikit_learn>0.21->pytorch_tabnet) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\yeonjun jeong\\anaconda3\\lib\\site-packages (from scikit_learn>0.21->pytorch_tabnet) (2.1.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\yeonjun jeong\\anaconda3\\lib\\site-packages (from torch<2.0,>=1.2->pytorch_tabnet) (3.7.4.3)\n",
      "Building wheels for collected packages: pytorch_tabnet\n",
      "  Building wheel for pytorch_tabnet (pyproject.toml): started\n",
      "  Building wheel for pytorch_tabnet (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pytorch_tabnet: filename=pytorch_tabnet-3.1.1-py3-none-any.whl size=42081 sha256=bab6dd5508a18878ce0663b72533570a63c3e980709cbfea02db9ee0b6c933eb\n",
      "  Stored in directory: C:\\Users\\Yeonjun Jeong\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-vhpbxtfk\\wheels\\33\\ec\\90\\ae88ee166d5a2eabee63ae802d0a6cb752cf7d25a6a8613941\n",
      "Successfully built pytorch_tabnet\n",
      "Installing collected packages: pytorch_tabnet\n",
      "Successfully installed pytorch_tabnet-3.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y typing \n",
    "# this should avoid  AttributeError: type object 'Callable' has no attribute '_abc_registry'\n",
    "\n",
    "!pip install  \"git+https://github.com/dreamquark-ai/tabnet.git@develop#egg=pytorch_tabnet\" --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "23f21f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.multitask import TabNetMultiTaskClassifier\n",
    "\n",
    "import torch\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, label_binarize, StandardScaler, MinMaxScaler,OrdinalEncoder\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn import model_selection\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fff5c2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('./pre_credit_df(fill_groupby)_final.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c71230b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['gender','car','reality','child_num','income_type','edu_type','family_type',\n",
    "                        'house_type','work_phone','phone','email','occyp_type','dup','family_category','occyp_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9f4e337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[categorical_columns] = data_df[categorical_columns].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6f91c890",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_Y = data_df['credit']\n",
    "credit_X = data_df.drop(['credit'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "20162146",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = StandardScaler()\n",
    "numeric_features = ['income_total','DAYS_EMPLOYED','family_size','begin_month','Age','cards']\n",
    "credit_X[numeric_features] = encoder.fit_transform(credit_X[numeric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c574c528",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2094e4b8ec1429a8c213e9e9b233961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "categorical_dims =  {}\n",
    "for col in tqdm(credit_X.columns):\n",
    "    if credit_X[col].dtype == object:\n",
    "        l_enc = LabelEncoder()\n",
    "        credit_X[col] = l_enc.fit_transform(credit_X[col].values)\n",
    "        categorical_columns.append(col)\n",
    "        categorical_dims[col] = len(l_enc.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5b66ff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [ col for col in credit_X.columns] \n",
    "\n",
    "cat_idxs = [ i for i, f in enumerate(features) if f in categorical_columns]\n",
    "\n",
    "cat_dims = [ categorical_dims[f] for i, f in enumerate(features) if f in categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e53be544",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(credit_X, credit_Y, test_size=0.2, random_state=0)\n",
    "y_train = np.array(y_train).reshape((-1,1))\n",
    "y_test = np.array(y_test).reshape((-1,1))\n",
    "X_train = np.array(x_train)\n",
    "X_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ee84a982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "clf = TabNetMultiTaskClassifier(n_steps=1,\n",
    "                                cat_idxs=cat_idxs,\n",
    "                                cat_dims=cat_dims,\n",
    "                                cat_emb_dim=1,\n",
    "                                optimizer_fn=torch.optim.Adam,\n",
    "                                optimizer_params=dict(lr=2e-2),\n",
    "                                scheduler_params={\"step_size\":50,\n",
    "                                                  \"gamma\":0.9},\n",
    "                                scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                                mask_type='entmax', \n",
    "                                lambda_sparse=0, \n",
    "                       \n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f527e67c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.92432 | val_0_logloss: 0.88085 |  0:00:05s\n",
      "epoch 1  | loss: 0.88039 | val_0_logloss: 0.86777 |  0:00:10s\n",
      "epoch 2  | loss: 0.86979 | val_0_logloss: 0.86298 |  0:00:15s\n",
      "epoch 3  | loss: 0.85887 | val_0_logloss: 0.84979 |  0:00:20s\n",
      "epoch 4  | loss: 0.84362 | val_0_logloss: 0.82801 |  0:00:26s\n",
      "epoch 5  | loss: 0.82636 | val_0_logloss: 0.80842 |  0:00:31s\n",
      "epoch 6  | loss: 0.81696 | val_0_logloss: 0.80212 |  0:00:37s\n",
      "epoch 7  | loss: 0.8105  | val_0_logloss: 0.79635 |  0:00:43s\n",
      "epoch 8  | loss: 0.81344 | val_0_logloss: 0.79921 |  0:00:49s\n",
      "epoch 9  | loss: 0.80731 | val_0_logloss: 0.7951  |  0:00:55s\n",
      "epoch 10 | loss: 0.80373 | val_0_logloss: 0.79853 |  0:01:01s\n",
      "epoch 11 | loss: 0.80239 | val_0_logloss: 0.80102 |  0:01:07s\n",
      "epoch 12 | loss: 0.80272 | val_0_logloss: 0.79162 |  0:01:12s\n",
      "epoch 13 | loss: 0.80013 | val_0_logloss: 0.80341 |  0:01:18s\n",
      "epoch 14 | loss: 0.79943 | val_0_logloss: 0.78786 |  0:01:24s\n",
      "epoch 15 | loss: 0.7978  | val_0_logloss: 0.79791 |  0:01:30s\n",
      "epoch 16 | loss: 0.79558 | val_0_logloss: 0.79003 |  0:01:36s\n",
      "epoch 17 | loss: 0.79386 | val_0_logloss: 0.79005 |  0:01:41s\n",
      "epoch 18 | loss: 0.7928  | val_0_logloss: 0.78504 |  0:01:47s\n",
      "epoch 19 | loss: 0.79108 | val_0_logloss: 0.79121 |  0:01:53s\n",
      "epoch 20 | loss: 0.79301 | val_0_logloss: 0.78703 |  0:01:58s\n",
      "epoch 21 | loss: 0.78836 | val_0_logloss: 0.79946 |  0:02:06s\n",
      "epoch 22 | loss: 0.7901  | val_0_logloss: 0.79088 |  0:02:15s\n",
      "epoch 23 | loss: 0.78903 | val_0_logloss: 0.79175 |  0:02:25s\n",
      "epoch 24 | loss: 0.78314 | val_0_logloss: 0.79263 |  0:02:34s\n",
      "epoch 25 | loss: 0.78347 | val_0_logloss: 0.78553 |  0:02:42s\n",
      "epoch 26 | loss: 0.77996 | val_0_logloss: 0.78404 |  0:02:52s\n",
      "epoch 27 | loss: 0.78121 | val_0_logloss: 0.79283 |  0:02:59s\n",
      "epoch 28 | loss: 0.77758 | val_0_logloss: 0.79756 |  0:03:08s\n",
      "epoch 29 | loss: 0.77795 | val_0_logloss: 0.78208 |  0:03:16s\n",
      "epoch 30 | loss: 0.77132 | val_0_logloss: 0.79117 |  0:03:24s\n",
      "epoch 31 | loss: 0.77475 | val_0_logloss: 0.78634 |  0:03:32s\n",
      "epoch 32 | loss: 0.7739  | val_0_logloss: 0.78775 |  0:03:38s\n",
      "epoch 33 | loss: 0.7731  | val_0_logloss: 0.78351 |  0:03:45s\n",
      "epoch 34 | loss: 0.77419 | val_0_logloss: 0.79038 |  0:03:50s\n",
      "epoch 35 | loss: 0.76971 | val_0_logloss: 0.79544 |  0:03:56s\n",
      "epoch 36 | loss: 0.76995 | val_0_logloss: 0.78563 |  0:04:01s\n",
      "epoch 37 | loss: 0.76975 | val_0_logloss: 0.79115 |  0:04:06s\n",
      "epoch 38 | loss: 0.76546 | val_0_logloss: 0.7997  |  0:04:12s\n",
      "epoch 39 | loss: 0.76592 | val_0_logloss: 0.78815 |  0:04:18s\n",
      "epoch 40 | loss: 0.76382 | val_0_logloss: 0.79045 |  0:04:23s\n",
      "epoch 41 | loss: 0.76056 | val_0_logloss: 0.78853 |  0:04:28s\n",
      "epoch 42 | loss: 0.76262 | val_0_logloss: 0.79004 |  0:04:34s\n",
      "epoch 43 | loss: 0.76087 | val_0_logloss: 0.79667 |  0:04:40s\n",
      "epoch 44 | loss: 0.75843 | val_0_logloss: 0.79331 |  0:04:45s\n",
      "epoch 45 | loss: 0.76    | val_0_logloss: 0.80095 |  0:04:51s\n",
      "epoch 46 | loss: 0.76187 | val_0_logloss: 0.78883 |  0:04:56s\n",
      "epoch 47 | loss: 0.75671 | val_0_logloss: 0.79368 |  0:05:02s\n",
      "epoch 48 | loss: 0.75566 | val_0_logloss: 0.79665 |  0:05:08s\n",
      "epoch 49 | loss: 0.75179 | val_0_logloss: 0.7966  |  0:05:14s\n",
      "epoch 50 | loss: 0.75264 | val_0_logloss: 0.79838 |  0:05:20s\n",
      "epoch 51 | loss: 0.75064 | val_0_logloss: 0.79856 |  0:05:27s\n",
      "epoch 52 | loss: 0.74804 | val_0_logloss: 0.79397 |  0:05:33s\n",
      "epoch 53 | loss: 0.74841 | val_0_logloss: 0.79836 |  0:05:40s\n",
      "epoch 54 | loss: 0.74659 | val_0_logloss: 0.79705 |  0:05:47s\n",
      "epoch 55 | loss: 0.7461  | val_0_logloss: 0.79261 |  0:05:54s\n",
      "epoch 56 | loss: 0.7453  | val_0_logloss: 0.79601 |  0:06:00s\n",
      "epoch 57 | loss: 0.74338 | val_0_logloss: 0.79548 |  0:06:07s\n",
      "epoch 58 | loss: 0.74362 | val_0_logloss: 0.80078 |  0:06:13s\n",
      "epoch 59 | loss: 0.74384 | val_0_logloss: 0.8005  |  0:06:19s\n",
      "epoch 60 | loss: 0.74167 | val_0_logloss: 0.79743 |  0:06:25s\n",
      "epoch 61 | loss: 0.7422  | val_0_logloss: 0.8026  |  0:06:30s\n",
      "epoch 62 | loss: 0.73995 | val_0_logloss: 0.80048 |  0:06:37s\n",
      "epoch 63 | loss: 0.74221 | val_0_logloss: 0.79411 |  0:06:42s\n",
      "epoch 64 | loss: 0.7377  | val_0_logloss: 0.79467 |  0:06:47s\n",
      "epoch 65 | loss: 0.73652 | val_0_logloss: 0.80087 |  0:06:53s\n",
      "epoch 66 | loss: 0.73795 | val_0_logloss: 0.8002  |  0:06:59s\n",
      "epoch 67 | loss: 0.73515 | val_0_logloss: 0.7939  |  0:07:06s\n",
      "epoch 68 | loss: 0.73699 | val_0_logloss: 0.80057 |  0:07:12s\n",
      "epoch 69 | loss: 0.73107 | val_0_logloss: 0.79443 |  0:07:18s\n",
      "epoch 70 | loss: 0.73529 | val_0_logloss: 0.79736 |  0:07:24s\n",
      "epoch 71 | loss: 0.73303 | val_0_logloss: 0.80336 |  0:07:30s\n",
      "epoch 72 | loss: 0.73864 | val_0_logloss: 0.80223 |  0:07:37s\n",
      "epoch 73 | loss: 0.73337 | val_0_logloss: 0.80294 |  0:07:44s\n",
      "epoch 74 | loss: 0.73507 | val_0_logloss: 0.80237 |  0:07:50s\n",
      "epoch 75 | loss: 0.73235 | val_0_logloss: 0.80173 |  0:07:57s\n",
      "epoch 76 | loss: 0.73266 | val_0_logloss: 0.80097 |  0:08:03s\n",
      "epoch 77 | loss: 0.73264 | val_0_logloss: 0.80225 |  0:08:10s\n",
      "epoch 78 | loss: 0.72728 | val_0_logloss: 0.80525 |  0:08:17s\n",
      "epoch 79 | loss: 0.72978 | val_0_logloss: 0.80046 |  0:08:24s\n",
      "\n",
      "Early stopping occurred at epoch 79 with best_epoch = 29 and best_val_0_logloss = 0.78208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 1000\n",
    "clf.fit(\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    eval_set = [(X_test,y_test)],\n",
    "    max_epochs=max_epochs ,\n",
    "    patience=50, # please be patient ^^\n",
    "    batch_size=1024,\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=1,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "53adf63b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
      "     -------------------------------------- 308.2/308.2 KB 9.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: PyYAML in c:\\users\\yeonjun jeong\\anaconda3\\lib\\site-packages (from optuna) (5.4.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\yeonjun jeong\\anaconda3\\lib\\site-packages (from optuna) (1.19.5)\n",
      "Collecting alembic\n",
      "  Downloading alembic-1.7.7-py3-none-any.whl (210 kB)\n",
      "     -------------------------------------- 210.7/210.7 KB 6.5 MB/s eta 0:00:00\n",
      "Collecting cmaes>=0.8.2\n",
      "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in c:\\users\\yeonjun jeong\\anaconda3\\lib\\site-packages (from optuna) (1.4.7)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yeonjun jeong\\anaconda3\\lib\\site-packages (from optuna) (4.59.0)\n",
      "Collecting cliff\n",
      "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
      "     ---------------------------------------- 81.0/81.0 KB 4.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy!=1.4.0 in c:\\users\\yeonjun jeong\\anaconda3\\lib\\site-packages (from optuna) (1.6.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yeonjun jeong\\anaconda3\\lib\\site-packages (from optuna) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\yeonjun jeong\\anaconda3\\lib\\site-packages (from packaging>=20.0->optuna) (2.4.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\yeonjun jeong\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.1.0->optuna) (1.0.0)\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-5.7.1-py3-none-any.whl (28 kB)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.4/78.4 KB ? eta 0:00:00\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\yeonjun jeong\\anaconda3\\lib\\site-packages (from alembic->optuna) (4.11.3)\n",
      "Collecting pbr!=2.1.0,>=2.0.0\n",
      "  Downloading pbr-5.9.0-py2.py3-none-any.whl (112 kB)\n",
      "     -------------------------------------- 112.3/112.3 KB 6.8 MB/s eta 0:00:00\n",
      "Collecting cmd2>=1.0.0\n",
      "  Downloading cmd2-2.4.1-py3-none-any.whl (146 kB)\n",
      "     -------------------------------------- 147.0/147.0 KB 9.1 MB/s eta 0:00:00\n",
      "Collecting autopage>=0.4.0\n",
      "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
      "Collecting PrettyTable>=0.7.2\n",
      "  Downloading prettytable-3.3.0-py3-none-any.whl (26 kB)\n",
      "Collecting stevedore>=2.0.1\n",
      "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
      "     ---------------------------------------- 49.7/49.7 KB ? eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\yeonjun jeong\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.4)\n",
      "Collecting pyreadline3\n",
      "  Downloading pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "     ---------------------------------------- 95.2/95.2 KB ? eta 0:00:00\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in c:\\users\\yeonjun jeong\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
      "Requirement already satisfied: attrs>=16.3.0 in c:\\users\\yeonjun jeong\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (20.3.0)\n",
      "Collecting pyperclip>=1.6\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\yeonjun jeong\\anaconda3\\lib\\site-packages (from importlib-metadata->alembic->optuna) (3.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\yeonjun jeong\\anaconda3\\lib\\site-packages (from Mako->alembic->optuna) (1.1.1)\n",
      "Building wheels for collected packages: pyperclip\n",
      "  Building wheel for pyperclip (setup.py): started\n",
      "  Building wheel for pyperclip (setup.py): finished with status 'done'\n",
      "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11107 sha256=e29a2aae1f023eb47413c7f32792b3dc94201701ba26afe205b479501a809124\n",
      "  Stored in directory: c:\\users\\yeonjun jeong\\appdata\\local\\pip\\cache\\wheels\\7f\\1a\\65\\84ff8c386bec21fca6d220ea1f5498a0367883a78dd5ba6122\n",
      "Successfully built pyperclip\n",
      "Installing collected packages: pyreadline3, pyperclip, PrettyTable, pbr, Mako, importlib-resources, colorlog, cmd2, cmaes, autopage, stevedore, alembic, cliff, optuna\n",
      "Successfully installed Mako-1.2.0 PrettyTable-3.3.0 alembic-1.7.7 autopage-0.5.0 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.1 colorlog-6.6.0 importlib-resources-5.7.1 optuna-2.10.0 pbr-5.9.0 pyperclip-1.8.2 pyreadline3-3.4.1 stevedore-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9b64eb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna import Trial, visualization\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d146dd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Objective(trial):\n",
    "    mask_type = trial.suggest_categorical(\"mask_type\", [\"entmax\", \"sparsemax\"])\n",
    "    n_steps = trial.suggest_int(\"n_steps\", 1, 5, step=1)\n",
    "    gamma = trial.suggest_float(\"gamma\", 1., 1.4, step=0.2)\n",
    "    n_shared = trial.suggest_int(\"n_shared\", 1, 3)\n",
    "    lambda_sparse = trial.suggest_float(\"lambda_sparse\", 1e-6, 1e-3, log=True)\n",
    "    tabnet_params = dict(cat_idxs=cat_idxs,cat_dims=cat_dims,cat_emb_dim=1,\n",
    "                     n_steps=n_steps, gamma=gamma,\n",
    "                     lambda_sparse=lambda_sparse, optimizer_fn=torch.optim.Adam,\n",
    "                     optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
    "                     mask_type=mask_type, n_shared=n_shared,\n",
    "                     scheduler_params={\"step_size\":50,\n",
    "                                                  \"gamma\":0.9},\n",
    "                     scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                     verbose=0,\n",
    "                     ) #early stopping\n",
    "    random_state = 0\n",
    "    num_folds= 5 # test_size = 0.2\n",
    "    str_kf = StratifiedKFold(n_splits = num_folds, shuffle = True, random_state = random_state)\n",
    "    CV_score_array    =[]\n",
    "    for train_index, test_index in str_kf.split(credit_X, credit_Y):\n",
    "        X_train, X_valid = credit_X.loc[train_index], credit_X.loc[test_index]\n",
    "        y_train, y_valid = credit_Y.loc[train_index], credit_Y.loc[test_index]\n",
    "        y_train = np.array(y_train).reshape((-1,1))\n",
    "        y_valid = np.array(y_valid).reshape((-1,1))\n",
    "        X_train = np.array(X_train)\n",
    "        X_valid = np.array(X_valid)\n",
    "        classifier = TabNetMultiTaskClassifier(**tabnet_params)\n",
    "        classifier.fit(X_train=X_train, y_train=y_train,\n",
    "                  eval_set=[(X_valid, y_valid)],\n",
    "                  patience=trial.suggest_int(\"patience\",low=15,high=30), max_epochs=trial.suggest_int('epochs', 1, 100),\n",
    "                  )\n",
    "        CV_score_array.append(classifier.best_cost)\n",
    "    avg = np.mean(CV_score_array)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a744528f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-10 00:46:57,480]\u001b[0m A new study created in memory with name: TabNet optimization\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 30 and best_val_0_logloss = 0.81075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 70 with best_epoch = 64 and best_val_0_logloss = 0.81006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 28 and best_val_0_logloss = 0.80507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 70 with best_epoch = 59 and best_val_0_logloss = 0.80458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 62 with best_epoch = 42 and best_val_0_logloss = 0.80108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2022-05-10 01:00:56,047]\u001b[0m Trial 0 finished with value: 0.8063089863802458 and parameters: {'mask_type': 'sparsemax', 'n_steps': 5, 'gamma': 1.4, 'n_shared': 2, 'lambda_sparse': 0.0004951269242265611, 'patience': 20, 'epochs': 70}. Best is trial 0 with value: 0.8063089863802458.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 14 with best_epoch = 13 and best_val_0_logloss = 0.81228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 14 with best_epoch = 12 and best_val_0_logloss = 0.81511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 14 with best_epoch = 13 and best_val_0_logloss = 0.81351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 14 with best_epoch = 12 and best_val_0_logloss = 0.81827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 14 with best_epoch = 13 and best_val_0_logloss = 0.81749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2022-05-10 01:02:03,442]\u001b[0m Trial 1 finished with value: 0.8153323324060848 and parameters: {'mask_type': 'entmax', 'n_steps': 1, 'gamma': 1.2, 'n_shared': 1, 'lambda_sparse': 5.002008483669687e-06, 'patience': 22, 'epochs': 14}. Best is trial 0 with value: 0.8063089863802458.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 77 with best_epoch = 55 and best_val_0_logloss = 0.80662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 71 with best_epoch = 41 and best_val_0_logloss = 0.81152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 77 with best_epoch = 66 and best_val_0_logloss = 0.79924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 77 with best_epoch = 75 and best_val_0_logloss = 0.80475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 77 with best_epoch = 50 and best_val_0_logloss = 0.80155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2022-05-10 01:17:36,455]\u001b[0m Trial 2 finished with value: 0.8047349894295064 and parameters: {'mask_type': 'sparsemax', 'n_steps': 4, 'gamma': 1.4, 'n_shared': 3, 'lambda_sparse': 0.0004080675653291991, 'patience': 30, 'epochs': 77}. Best is trial 2 with value: 0.8047349894295064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 57 with best_epoch = 41 and best_val_0_logloss = 0.80066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 58 with best_epoch = 42 and best_val_0_logloss = 0.80359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 19 and best_val_0_logloss = 0.80664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 49 with best_epoch = 33 and best_val_0_logloss = 0.80381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 67 with best_epoch = 51 and best_val_0_logloss = 0.79572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2022-05-10 01:24:19,571]\u001b[0m Trial 3 finished with value: 0.8020860768345622 and parameters: {'mask_type': 'entmax', 'n_steps': 2, 'gamma': 1.4, 'n_shared': 2, 'lambda_sparse': 0.00019919668502755013, 'patience': 16, 'epochs': 67}. Best is trial 3 with value: 0.8020860768345622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 31 with best_epoch = 17 and best_val_0_logloss = 0.80591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 31 with best_epoch = 29 and best_val_0_logloss = 0.80846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 31 with best_epoch = 27 and best_val_0_logloss = 0.80366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 31 with best_epoch = 28 and best_val_0_logloss = 0.80459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 31 with best_epoch = 19 and best_val_0_logloss = 0.80377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2022-05-10 01:29:37,042]\u001b[0m Trial 4 finished with value: 0.8052776662047867 and parameters: {'mask_type': 'entmax', 'n_steps': 3, 'gamma': 1.4, 'n_shared': 3, 'lambda_sparse': 0.00031705680508291057, 'patience': 30, 'epochs': 31}. Best is trial 3 with value: 0.8020860768345622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 59 with best_epoch = 37 and best_val_0_logloss = 0.80882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 80 with best_epoch = 72 and best_val_0_logloss = 0.8051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 80 with best_epoch = 79 and best_val_0_logloss = 0.7989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 80 with best_epoch = 74 and best_val_0_logloss = 0.80053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 39 and best_val_0_logloss = 0.80347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2022-05-10 01:38:42,037]\u001b[0m Trial 5 finished with value: 0.8033631239445661 and parameters: {'mask_type': 'sparsemax', 'n_steps': 3, 'gamma': 1.0, 'n_shared': 1, 'lambda_sparse': 3.587649556591382e-06, 'patience': 22, 'epochs': 80}. Best is trial 3 with value: 0.8020860768345622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 32 and best_val_0_logloss = 0.80847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 63 with best_epoch = 43 and best_val_0_logloss = 0.80801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 67 with best_epoch = 47 and best_val_0_logloss = 0.80262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 72 with best_epoch = 52 and best_val_0_logloss = 0.80576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 72 with best_epoch = 52 and best_val_0_logloss = 0.80028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2022-05-10 01:52:21,740]\u001b[0m Trial 6 finished with value: 0.8050249765824751 and parameters: {'mask_type': 'sparsemax', 'n_steps': 5, 'gamma': 1.2, 'n_shared': 2, 'lambda_sparse': 9.340503365756344e-05, 'patience': 20, 'epochs': 94}. Best is trial 3 with value: 0.8020860768345622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 25 with best_epoch = 19 and best_val_0_logloss = 0.8109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 25 with best_epoch = 24 and best_val_0_logloss = 0.81218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 25 with best_epoch = 23 and best_val_0_logloss = 0.8056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 25 with best_epoch = 19 and best_val_0_logloss = 0.80855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 25 with best_epoch = 23 and best_val_0_logloss = 0.80906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2022-05-10 01:55:31,172]\u001b[0m Trial 7 finished with value: 0.8092580900310452 and parameters: {'mask_type': 'sparsemax', 'n_steps': 3, 'gamma': 1.4, 'n_shared': 1, 'lambda_sparse': 4.21337799116908e-06, 'patience': 21, 'epochs': 25}. Best is trial 3 with value: 0.8020860768345622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 72 with best_epoch = 57 and best_val_0_logloss = 0.80856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 38 and best_val_0_logloss = 0.81315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 68 with best_epoch = 53 and best_val_0_logloss = 0.80055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 73 with best_epoch = 58 and best_val_0_logloss = 0.80493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 68 with best_epoch = 53 and best_val_0_logloss = 0.80095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2022-05-10 02:04:14,106]\u001b[0m Trial 8 finished with value: 0.8056288398963234 and parameters: {'mask_type': 'sparsemax', 'n_steps': 3, 'gamma': 1.2, 'n_shared': 1, 'lambda_sparse': 3.788901420200359e-05, 'patience': 15, 'epochs': 100}. Best is trial 3 with value: 0.8020860768345622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 31 and best_val_0_logloss = 0.80695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 32 and best_val_0_logloss = 0.8116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_val_0_logloss = 0.81343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 73 with best_epoch = 66 and best_val_0_logloss = 0.80436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 32 and best_val_0_logloss = 0.80298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2022-05-10 02:13:17,031]\u001b[0m Trial 9 finished with value: 0.8078647343567251 and parameters: {'mask_type': 'sparsemax', 'n_steps': 3, 'gamma': 1.2, 'n_shared': 3, 'lambda_sparse': 1.1703022747056252e-05, 'patience': 20, 'epochs': 73}. Best is trial 3 with value: 0.8020860768345622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 45 with best_epoch = 35 and best_val_0_logloss = 0.8054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 12 and best_val_0_logloss = 0.81145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 18 and best_val_0_logloss = 0.80087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 45 with best_epoch = 32 and best_val_0_logloss = 0.80039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 45 with best_epoch = 32 and best_val_0_logloss = 0.80673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2022-05-10 02:16:41,088]\u001b[0m Trial 10 finished with value: 0.8049668238796264 and parameters: {'mask_type': 'entmax', 'n_steps': 1, 'gamma': 1.0, 'n_shared': 2, 'lambda_sparse': 9.015530953804688e-05, 'patience': 16, 'epochs': 45}. Best is trial 3 with value: 0.8020860768345622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 22 and best_val_0_logloss = 0.80853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 21 and best_val_0_logloss = 0.80802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 17 and best_val_0_logloss = 0.79866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 56 with best_epoch = 30 and best_val_0_logloss = 0.79847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 57 with best_epoch = 44 and best_val_0_logloss = 0.79523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2022-05-10 02:22:04,103]\u001b[0m Trial 11 finished with value: 0.801780888402828 and parameters: {'mask_type': 'entmax', 'n_steps': 2, 'gamma': 1.0, 'n_shared': 1, 'lambda_sparse': 2.46686420365748e-06, 'patience': 26, 'epochs': 57}. Best is trial 11 with value: 0.801780888402828.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 55 with best_epoch = 43 and best_val_0_logloss = 0.80143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 55 with best_epoch = 50 and best_val_0_logloss = 0.80788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 55 with best_epoch = 51 and best_val_0_logloss = 0.80181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 11 and best_val_0_logloss = 0.80813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 55 with best_epoch = 35 and best_val_0_logloss = 0.79917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2022-05-10 02:28:04,217]\u001b[0m Trial 12 finished with value: 0.803684347786078 and parameters: {'mask_type': 'entmax', 'n_steps': 2, 'gamma': 1.0, 'n_shared': 2, 'lambda_sparse': 1.1958741286162654e-06, 'patience': 27, 'epochs': 55}. Best is trial 11 with value: 0.801780888402828.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 18 and best_val_0_logloss = 0.80574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 55 with best_epoch = 36 and best_val_0_logloss = 0.80187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 55 with best_epoch = 50 and best_val_0_logloss = 0.80005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 55 with best_epoch = 38 and best_val_0_logloss = 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 55 with best_epoch = 47 and best_val_0_logloss = 0.80292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2022-05-10 02:33:34,623]\u001b[0m Trial 13 finished with value: 0.8021144577848218 and parameters: {'mask_type': 'entmax', 'n_steps': 2, 'gamma': 1.0, 'n_shared': 1, 'lambda_sparse': 0.000961101932153076, 'patience': 25, 'epochs': 55}. Best is trial 11 with value: 0.801780888402828.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 45 with best_epoch = 28 and best_val_0_logloss = 0.8088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 45 with best_epoch = 40 and best_val_0_logloss = 0.80463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 45 with best_epoch = 26 and best_val_0_logloss = 0.80458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 9 and best_val_0_logloss = 0.80661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 45 with best_epoch = 37 and best_val_0_logloss = 0.80287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2022-05-10 02:38:43,650]\u001b[0m Trial 14 finished with value: 0.8054971763220508 and parameters: {'mask_type': 'entmax', 'n_steps': 2, 'gamma': 1.2, 'n_shared': 2, 'lambda_sparse': 1.1601654302459105e-06, 'patience': 25, 'epochs': 45}. Best is trial 11 with value: 0.801780888402828.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 30 and best_val_0_logloss = 0.80435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 26 and best_val_0_logloss = 0.80654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 17 and best_val_0_logloss = 0.80367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 49 with best_epoch = 31 and best_val_0_logloss = 0.79708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 49 with best_epoch = 31 and best_val_0_logloss = 0.80338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2022-05-10 02:43:28,904]\u001b[0m Trial 15 finished with value: 0.8030032101976812 and parameters: {'mask_type': 'entmax', 'n_steps': 2, 'gamma': 1.4, 'n_shared': 1, 'lambda_sparse': 2.3523251906971636e-05, 'patience': 18, 'epochs': 56}. Best is trial 11 with value: 0.801780888402828.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 67 with best_epoch = 54 and best_val_0_logloss = 0.80772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 58 with best_epoch = 33 and best_val_0_logloss = 0.80791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 26 and best_val_0_logloss = 0.80762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 67 with best_epoch = 57 and best_val_0_logloss = 0.79547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 19 and best_val_0_logloss = 0.80394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2022-05-10 02:49:06,843]\u001b[0m Trial 16 finished with value: 0.8045303595367447 and parameters: {'mask_type': 'entmax', 'n_steps': 1, 'gamma': 1.0, 'n_shared': 3, 'lambda_sparse': 0.00011056728251809648, 'patience': 25, 'epochs': 67}. Best is trial 11 with value: 0.801780888402828.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 3 with best_epoch = 2 and best_val_0_logloss = 0.86137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 3 with best_epoch = 2 and best_val_0_logloss = 0.85706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 3 with best_epoch = 2 and best_val_0_logloss = 0.84861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 3 with best_epoch = 2 and best_val_0_logloss = 0.85784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 3 with best_epoch = 2 and best_val_0_logloss = 0.83594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2022-05-10 02:49:44,766]\u001b[0m Trial 17 finished with value: 0.852164513262981 and parameters: {'mask_type': 'entmax', 'n_steps': 4, 'gamma': 1.2, 'n_shared': 2, 'lambda_sparse': 3.0273301638996312e-05, 'patience': 27, 'epochs': 3}. Best is trial 11 with value: 0.801780888402828.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 25 and best_val_0_logloss = 0.8052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 64 with best_epoch = 47 and best_val_0_logloss = 0.80289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 16 and best_val_0_logloss = 0.80333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 9 and best_val_0_logloss = 0.80836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 22 and best_val_0_logloss = 0.80277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2022-05-10 02:54:45,244]\u001b[0m Trial 18 finished with value: 0.8045110654254277 and parameters: {'mask_type': 'entmax', 'n_steps': 2, 'gamma': 1.2, 'n_shared': 2, 'lambda_sparse': 0.0001719454231113883, 'patience': 17, 'epochs': 87}. Best is trial 11 with value: 0.801780888402828.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 37 with best_epoch = 29 and best_val_0_logloss = 0.80723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 37 with best_epoch = 23 and best_val_0_logloss = 0.80682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 37 with best_epoch = 21 and best_val_0_logloss = 0.80435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 37 with best_epoch = 23 and best_val_0_logloss = 0.80592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 37 with best_epoch = 25 and best_val_0_logloss = 0.80601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2022-05-10 02:57:39,620]\u001b[0m Trial 19 finished with value: 0.8060652380364536 and parameters: {'mask_type': 'entmax', 'n_steps': 1, 'gamma': 1.4, 'n_shared': 1, 'lambda_sparse': 1.471592717887421e-05, 'patience': 27, 'epochs': 37}. Best is trial 11 with value: 0.801780888402828.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 65 with best_epoch = 62 and best_val_0_logloss = 0.79854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 26 and best_val_0_logloss = 0.81143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 63 with best_epoch = 39 and best_val_0_logloss = 0.79937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 65 with best_epoch = 58 and best_val_0_logloss = 0.80288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 65 with best_epoch = 62 and best_val_0_logloss = 0.80072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2022-05-10 03:10:05,432]\u001b[0m Trial 20 finished with value: 0.8025871303519274 and parameters: {'mask_type': 'entmax', 'n_steps': 4, 'gamma': 1.0, 'n_shared': 3, 'lambda_sparse': 4.4808279255698205e-05, 'patience': 24, 'epochs': 65}. Best is trial 11 with value: 0.801780888402828.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 59 with best_epoch = 49 and best_val_0_logloss = 0.80407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 59 with best_epoch = 57 and best_val_0_logloss = 0.802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 59 with best_epoch = 37 and best_val_0_logloss = 0.8011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 58 with best_epoch = 34 and best_val_0_logloss = 0.80277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 59 with best_epoch = 44 and best_val_0_logloss = 0.79664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2022-05-10 03:16:18,296]\u001b[0m Trial 21 finished with value: 0.8013170251718339 and parameters: {'mask_type': 'entmax', 'n_steps': 2, 'gamma': 1.0, 'n_shared': 1, 'lambda_sparse': 0.0009587626576470115, 'patience': 24, 'epochs': 59}. Best is trial 21 with value: 0.8013170251718339.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 60 with best_epoch = 42 and best_val_0_logloss = 0.79897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 24 and best_val_0_logloss = 0.80883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 60 with best_epoch = 52 and best_val_0_logloss = 0.80052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 27 and best_val_0_logloss = 0.80115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 49 with best_epoch = 26 and best_val_0_logloss = 0.8023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2022-05-10 03:21:57,986]\u001b[0m Trial 22 finished with value: 0.8023538047633487 and parameters: {'mask_type': 'entmax', 'n_steps': 2, 'gamma': 1.0, 'n_shared': 1, 'lambda_sparse': 0.0008963758214100781, 'patience': 23, 'epochs': 60}. Best is trial 21 with value: 0.8013170251718339.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 47 with best_epoch = 20 and best_val_0_logloss = 0.80724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 47 with best_epoch = 24 and best_val_0_logloss = 0.81315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 47 with best_epoch = 31 and best_val_0_logloss = 0.80208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 47 with best_epoch = 21 and best_val_0_logloss = 0.80459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 47 with best_epoch = 36 and best_val_0_logloss = 0.79999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2022-05-10 03:26:49,686]\u001b[0m Trial 23 finished with value: 0.8054094558911856 and parameters: {'mask_type': 'entmax', 'n_steps': 2, 'gamma': 1.0, 'n_shared': 1, 'lambda_sparse': 0.00020223894801827349, 'patience': 28, 'epochs': 47}. Best is trial 21 with value: 0.8013170251718339.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 63 with best_epoch = 40 and best_val_0_logloss = 0.80965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 27 and best_val_0_logloss = 0.80668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 21 and best_val_0_logloss = 0.80629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 49 with best_epoch = 26 and best_val_0_logloss = 0.80816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 30 and best_val_0_logloss = 0.80843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2022-05-10 03:31:13,854]\u001b[0m Trial 24 finished with value: 0.8078426787890809 and parameters: {'mask_type': 'entmax', 'n_steps': 1, 'gamma': 1.0, 'n_shared': 1, 'lambda_sparse': 0.0005324826523203958, 'patience': 23, 'epochs': 64}. Best is trial 21 with value: 0.8013170251718339.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 38 with best_epoch = 24 and best_val_0_logloss = 0.80168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 15 and best_val_0_logloss = 0.806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 38 with best_epoch = 21 and best_val_0_logloss = 0.79966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 38 with best_epoch = 30 and best_val_0_logloss = 0.80031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 13 and best_val_0_logloss = 0.80294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2022-05-10 03:34:52,590]\u001b[0m Trial 25 finished with value: 0.802119486082945 and parameters: {'mask_type': 'entmax', 'n_steps': 2, 'gamma': 1.2, 'n_shared': 1, 'lambda_sparse': 0.00022791573716282308, 'patience': 18, 'epochs': 38}. Best is trial 21 with value: 0.8013170251718339.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 56 with best_epoch = 28 and best_val_0_logloss = 0.802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 80 with best_epoch = 58 and best_val_0_logloss = 0.80415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 67 with best_epoch = 39 and best_val_0_logloss = 0.80227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 80 with best_epoch = 61 and best_val_0_logloss = 0.80184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 18 and best_val_0_logloss = 0.80301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2022-05-10 03:42:47,687]\u001b[0m Trial 26 finished with value: 0.802654777909568 and parameters: {'mask_type': 'entmax', 'n_steps': 2, 'gamma': 1.0, 'n_shared': 2, 'lambda_sparse': 2.1878205741195603e-06, 'patience': 28, 'epochs': 80}. Best is trial 21 with value: 0.8013170251718339.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 51 with best_epoch = 41 and best_val_0_logloss = 0.80955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 51 with best_epoch = 33 and best_val_0_logloss = 0.80373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 51 with best_epoch = 32 and best_val_0_logloss = 0.80541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 51 with best_epoch = 44 and best_val_0_logloss = 0.80455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 51 with best_epoch = 32 and best_val_0_logloss = 0.80319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2022-05-10 03:46:38,312]\u001b[0m Trial 27 finished with value: 0.8052851257790422 and parameters: {'mask_type': 'entmax', 'n_steps': 1, 'gamma': 1.2, 'n_shared': 1, 'lambda_sparse': 8.205973653636803e-06, 'patience': 26, 'epochs': 51}. Best is trial 21 with value: 0.8013170251718339.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 89 with best_epoch = 82 and best_val_0_logloss = 0.7959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 89 with best_epoch = 65 and best_val_0_logloss = 0.79337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 89 with best_epoch = 70 and best_val_0_logloss = 0.79339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 89 with best_epoch = 72 and best_val_0_logloss = 0.79536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 22 and best_val_0_logloss = 0.79449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2022-05-10 03:58:46,829]\u001b[0m Trial 28 finished with value: 0.7945013596189942 and parameters: {'mask_type': 'entmax', 'n_steps': 3, 'gamma': 1.0, 'n_shared': 2, 'lambda_sparse': 5.954980130207787e-05, 'patience': 24, 'epochs': 89}. Best is trial 28 with value: 0.7945013596189942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 56 with best_epoch = 32 and best_val_0_logloss = 0.79802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 67 with best_epoch = 43 and best_val_0_logloss = 0.80471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 16 and best_val_0_logloss = 0.80105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 62 with best_epoch = 38 and best_val_0_logloss = 0.79966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 18 and best_val_0_logloss = 0.80484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2022-05-10 04:07:14,000]\u001b[0m Trial 29 finished with value: 0.8016565084254038 and parameters: {'mask_type': 'entmax', 'n_steps': 4, 'gamma': 1.0, 'n_shared': 1, 'lambda_sparse': 5.708781880701445e-05, 'patience': 24, 'epochs': 87}. Best is trial 28 with value: 0.7945013596189942.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\", study_name='TabNet optimization')\n",
    "study.optimize(Objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3ba4b5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mask_type': 'entmax', 'n_steps': 3, 'gamma': 1.0, 'n_shared': 2, 'lambda_sparse': 5.954980130207787e-05, 'patience': 24, 'epochs': 89}\n"
     ]
    }
   ],
   "source": [
    "TabNet_params = study.best_params\n",
    "print(TabNet_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9f70e11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_params = dict( n_steps=TabNet_params['n_steps'], gamma=TabNet_params['gamma'],\n",
    "                     lambda_sparse=TabNet_params['lambda_sparse'], optimizer_fn=torch.optim.Adam,\n",
    "                     optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
    "                     mask_type=TabNet_params['mask_type'], n_shared=TabNet_params['n_shared'],\n",
    "                      scheduler_params={\"step_size\":50,\n",
    "                                                  \"gamma\":0.9},\n",
    "                     scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                     verbose=0,\n",
    "                     )\n",
    "epochs = TabNet_params['epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "9be53a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(credit_X, credit_Y, test_size=0.2, random_state=0)\n",
    "y_train = np.array(y_train).reshape((-1,1))\n",
    "y_test = np.array(y_test).reshape((-1,1))\n",
    "X_train = np.array(x_train)\n",
    "X_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "cf0f715b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 21 and best_val_0_logloss = 0.79013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonjun Jeong\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "clf = TabNetMultiTaskClassifier(**final_params)\n",
    "\n",
    "clf.fit(\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    eval_set = [(X_test,y_test)],\n",
    "    patience=TabNet_params['patience'], max_epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a5db42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
